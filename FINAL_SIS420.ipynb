{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaK7DiL1u6QQVJIGytRTEl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zayoco/SIS-420-IA/blob/main/FINAL_SIS420.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlt9rZQck586"
      },
      "outputs": [],
      "source": [
        "# Biblioteca de aprendizaje automatico\n",
        "import sklearn\n",
        "# Biblioteca de trazado 2D\n",
        "import matplotlib\n",
        "# Biblioteca para la informacion cientifica\n",
        "import numpy as np\n",
        "# Biblioteca y módulo para crear y personalizar graficos y figuras\n",
        "import matplotlib.pyplot as plt\n",
        "# Mostrar las graficas en linea en el propio notebook\n",
        "%matplotlib inline\n",
        "# Biblioteca para manipulacion y analisis de datos\n",
        "import pandas as pd\n",
        "# Biblioteca, modulo y funcion, la funcion se utiliza para dividir un dataset en conjuntos de entrenamiento y prueba\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ONbXz2MpZqC",
        "outputId": "b93b7eb9-491c-4ca3-ec16-9c75adc2e454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lee los datos del archivo CSV utilizando la función read_csv() de pandas y los almacena en un DataFrame llamado data.\n",
        "data = pd.read_csv('/content/drive/MyDrive/DATASETS/dataset_5.csv')\n",
        "data\n",
        "\n",
        "# Extrae las características (X) del DataFrame data utilizando la función iloc[] de pandas,\n",
        "# seleccionando todas las filas (:) y todas las columnas excepto la primera (1:), y las almacena en la variable X.\n",
        "X = data.iloc[:, 1:].values\n",
        "# Extrae las etiquetas (números escritos a mano) del DataFrame data seleccionando la columna 'label'\n",
        "# y las almacena en la variable y.\n",
        "#y = data[0,:].values\n",
        "\n",
        "# Divide los datos en conjuntos de entrenamiento y prueba utilizando la función train_test_split().\n",
        "# El parámetro test_size=0.2 especifica que el 20% de los datos se utilizarán como conjunto de prueba,\n",
        "# mientras que el 80% se utilizará como conjunto de entrenamiento. El parámetro random_state=42 asegura\n",
        "# que la división sea reproducible.\n",
        "#x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "x_train, x_test = train_test_split(X, test_size=0.2, random_state=42)\n",
        "\n",
        "# Imprime las formas de los conjuntos de entrenamiento y las etiquetas de entrenamiento\n",
        "print('Training Data: {}'.format(x_train.shape))\n",
        "print(X)\n",
        "#print('Training Labels: {}'.format(y_train.shape))\n",
        "#print(y)"
      ],
      "metadata": {
        "id": "A7gHowZ-o-57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8a2073eb-0551-4b75-c6be-6020be427d96"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data: (40000, 3071)\n",
            "[[ 32 146  54 ... 255 255 255]\n",
            " [139 205 125 ... 255 255 255]\n",
            " [ 39 122 255 ... 255 255 255]\n",
            " ...\n",
            " [ 42  62 123 ... 255 255 255]\n",
            " [ 24  14  82 ... 255 255 255]\n",
            " [ 30 162  86 ... 255 255 255]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime las formas de los conjuntos de prueba y las etiquetas de prueba\n",
        "print('Testing Data: {}'.format(x_test.shape))\n",
        "#print('Testing Labels: {}'.format(y_test.shape))"
      ],
      "metadata": {
        "id": "Hc5k3TpepFoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b5c3aae-da70-45ca-9305-fd2a48a4b6ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Data: (10000, 3071)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = x_train\n",
        "#Y = y_train\n",
        "\n",
        "# Normaliza los valores de píxeles en las imágenes para que estén en el rango de 0 a 1.\n",
        "# Para ello, se convierten los valores de píxeles a valores de tipo float y luego se dividen por 255,\n",
        "# que es el valor máximo de un píxel en una imagen en escala de grises (0 representa el negro y 255 el blanco).\n",
        "X = X.astype(float) / 255.\n",
        "\n",
        "# Imprime las formas de la matriz X y la primera imagen en X para verificar los cambios realizados.\n",
        "print(X.shape)\n",
        "print(X[0].shape)"
      ],
      "metadata": {
        "id": "Up9R3Uv5pIUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8adbe219-6a72-435f-db21-14da57ebdb95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 3071)\n",
            "(3071,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa la clase MiniBatchKMeans, algoritmo de agrupamiento K-Means que utiliza mini lotes de datos para acelerar el proceso\n",
        "# de entrenamiento en grandes conjuntos de datos\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "# Calcula el número de dígitos únicos en el conjunto de datos de prueba y_test utilizando np.unique\n",
        "n_digits = len(np.unique(y_test))\n",
        "print(n_digits)\n",
        "\n",
        "# Inicializa un objeto de la clase MiniBatchKMeans con el número de clusters igual al número de dígitos únicos\n",
        "# en el conjunto de datos de prueba. Esto prepara el modelo K-means para agrupar los datos.\n",
        "kmeans = MiniBatchKMeans(n_clusters = n_digits)\n",
        "# Ajusta el modelo K-means a los datos de entrenamiento X utilizando el método fit().\n",
        "# Esto lleva a cabo el proceso de agrupamiento, donde los centroides se ajustan a los datos para minimizar\n",
        "# la distancia entre los puntos(imagen) de datos y sus centroides respectivos.\n",
        "\n",
        "# Inicialización de centroides: El método inicializa los centroides iniciales.\n",
        "# Estos centroides son puntos en el espacio de características alrededor de los cuales se agruparán los datos.\n",
        "\n",
        "# Asignación de puntos a clusters: Luego, para cada punto en el conjunto de datos X,\n",
        "# el método determina a qué cluster pertenece calculando la distancia entre el punto\n",
        "# y los centroides. Cada punto se asigna al cluster cuyo centroide está más cerca de él.\n",
        "\n",
        "# Actualización de centroides: Después de asignar todos los puntos a clusters,\n",
        "# el método actualiza los centroides recalculando sus posiciones como el\n",
        "# promedio de las posiciones de todos los puntos asignados a ese cluster.\n",
        "# Este paso ajusta los centroides para que estén más cerca de los puntos asignados a sus respectivos clusters.\n",
        "\n",
        "# Iteración: Los pasos 2 y 3 se repiten iterativamente hasta que se cumple un criterio de convergencia,\n",
        "# como alcanzar un número máximo de iteraciones o hasta que la diferencia entre las posiciones de los\n",
        "# centroides en iteraciones consecutivas sea menor que una cierta tolerancia.\n",
        "\n",
        "# Resultado: Una vez que se alcanza la convergencia, el método fit(X) devuelve el objeto kmeans\n",
        "# ajustado, que ahora contiene información sobre los centroides finales y las asignaciones de puntos a clusters.\n",
        "kmeans.fit(X)"
      ],
      "metadata": {
        "id": "DIjh9LQLyeAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# contiene las etiquetas de clúster asignadas por el algoritmo K-means a cada punto de datos en el conjunto de entrenamiento X.\n",
        "kmeans.labels_"
      ],
      "metadata": {
        "id": "X7xn5U2xylNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans.labels_.shape"
      ],
      "metadata": {
        "id": "oeQxPr8PypI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ASIGNACION DE ETIQUETAS DE CLUSTER\n",
        "def infer_cluster_labels(kmeans, actual_labels):\n",
        "    # Esta función toma el modelo K-means ajustado kmeans y las etiquetas reales actual_labels.\n",
        "    # Asocia la etiqueta más probable con cada grupo en el modelo KMeans y devuelve un diccionario que asigna clusters a etiquetas\n",
        "\n",
        "    # Inicializa un diccionario vacío para almacenar las etiquetas inferidas para cada cluster.\n",
        "    inferred_labels = {}\n",
        "\n",
        "    # itera sobre cada cluster en el modelo K-means.\n",
        "    for i in range(kmeans.n_clusters):\n",
        "\n",
        "        # Utiliza np.where() para encontrar los índices de los puntos en el cluster actual i.\n",
        "        labels = []\n",
        "        index = np.where(kmeans.labels_ == i)\n",
        "\n",
        "        # Agrega las etiquetas reales correspondientes a los puntos en el cluster actual al final de la lista labels.\n",
        "        labels.append(actual_labels[index])\n",
        "\n",
        "        # Determina la etiqueta más común en el cluster actual\n",
        "        # Si solo hay una etiqueta en el cluster (es decir, len(labels[0]) == 1), utiliza np.bincount(labels[0]) para\n",
        "        # contar las ocurrencias de cada etiqueta en el cluster.\n",
        "        if len(labels[0]) == 1:\n",
        "            counts = np.bincount(labels[0])\n",
        "        else:\n",
        "            # Si hay más de una etiqueta en el cluster, utiliza np.squeeze(labels) para convertir la lista de etiquetas\n",
        "            # en un array unidimensional y luego cuenta las ocurrencias de cada etiqueta.\n",
        "            counts = np.bincount(np.squeeze(labels))\n",
        "\n",
        "        # Comprueba si la etiqueta más común en el cluster actual ya está presente en el diccionario inferred_labels.\n",
        "        if np.argmax(counts) in inferred_labels:\n",
        "            # agregue el nuevo número a la matriz existente en esta ranura\n",
        "            inferred_labels[np.argmax(counts)].append(i)\n",
        "        else:\n",
        "            # crear una nueva matriz en esta ranura\n",
        "            inferred_labels[np.argmax(counts)] = [i]\n",
        "\n",
        "    return inferred_labels\n",
        "\n",
        "def infer_data_labels(X_labels, cluster_labels):\n",
        "    # Esta función toma las etiquetas de datos X_labels y el diccionario de clusters a etiquetas cluster_labels.\n",
        "    # Determina la etiqueta para cada matriz en base al cluster al que se ha asignado y devuelve las etiquetas\n",
        "    # previstas para cada matriz. Itera a través de cada cluster en X_labels, busca el cluster en el diccionario\n",
        "    # cluster_labels y asigna la etiqueta correspondiente.\n",
        "\n",
        "    # Crea un array de ceros con la misma longitud que la lista de etiquetas de los datos de entrada (X_labels).\n",
        "    # Este array será utilizado para almacenar las etiquetas inferidas para cada punto de datos.\n",
        "    predicted_labels = np.zeros(len(X_labels)).astype(np.uint8)\n",
        "\n",
        "    # itera sobre cada etiqueta de cluster en la lista X_labels.\n",
        "    for i, cluster in enumerate(X_labels):\n",
        "        # se itera a través de cada par clave-valor en el diccionario cluster_labels utilizando el bucle for key,\n",
        "        # value in cluster_labels.items():.\n",
        "        for key, value in cluster_labels.items():\n",
        "            # Se comprueba si la etiqueta del cluster actual (cluster) está presente en los valores del diccionario cluster_labels\n",
        "            if cluster in value:\n",
        "                # Si el cluster actual está presente en los valores del diccionario, se asigna la etiqueta correspondiente\n",
        "                # (clave del diccionario) al punto de datos en el array predicted_labels en la posición i.\n",
        "                predicted_labels[i] = key\n",
        "\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "rv12F-mPyvPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Llama a la función infer_cluster_labels(kmeans, Y) para obtener un diccionario de clusters asignados a cada etiqueta.\n",
        "# Esto se almacena en la variable cluster_labels.\n",
        "cluster_labels = infer_cluster_labels(kmeans, Y)\n",
        "# Utiliza el método predict() del objeto kmeans para predecir los clusters de los datos de entrada X.\n",
        "# Estos clusters se almacenan en la variable X_clusters.\n",
        "X_clusters = kmeans.predict(X)\n",
        "# Llama a la función infer_data_labels(X_clusters, cluster_labels) para obtener las etiquetas inferidas para cada punto\n",
        "# de datos en base a los clusters predichos y el diccionario de clusters a etiquetas. Estas etiquetas se almacenan\n",
        "# en la variable predicted_labels.\n",
        "predicted_labels = infer_data_labels(X_clusters, cluster_labels)\n",
        "# Imprime las etiquetas inferidas para los primeros 20 puntos de datos (predicted_labels[:20])\n",
        "# y las etiquetas reales de estos puntos de datos (Y[:20]).\n",
        "print (predicted_labels[:50])\n",
        "print (Y[:50])"
      ],
      "metadata": {
        "id": "P7L2ZVkYy7Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#El punto más representativo dentro de cada grupo se llama centroide. Si estuviéramos tratando con puntos X,Y,\n",
        "#el centroide sería simplemente un punto en la gráfica. Sin embargo, dado que estamos usando matrices de longitud 784,\n",
        "#nuestro centroide también será una matriz de longitud 784. Podemos remodelar esta matriz nuevamente en una imagen de 28 por 28 píxeles y trazarla.\n",
        "\n",
        "Estos gráficos mostrarán la imagen más representativa de cada grupo\n",
        "\n",
        "# Inicializar y ajustar el algoritmo KMeans\n",
        "kmeans = MiniBatchKMeans(n_clusters = 16)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# registrar valores de centroide\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "# remodelar los centroides en imágenes\n",
        "images = centroids.reshape(16, 28, 28)\n",
        "images *= 255\n",
        "images = images.astype(np.uint8)\n",
        "\n",
        "# determinar las etiquetas del grupo\n",
        "cluster_labels = infer_cluster_labels(kmeans, Y)\n",
        "\n",
        "# crear figura con subplots usando matplotlib.pyplot\n",
        "fig, axs = plt.subplots(4, 4, figsize = (20, 20))\n",
        "plt.gray()\n",
        "\n",
        "# recorrer subplots y agregar imágenes de centroide\n",
        "for i, ax in enumerate(axs.flat):\n",
        "\n",
        "    # determinar la etiqueta inferida usando el diccionario cluster_labels\n",
        "    for key, value in cluster_labels.items():\n",
        "        if i in value:\n",
        "            ax.set_title('Inferred Label: {}'.format(key))\n",
        "\n",
        "    # agregar imagen a la trama secundaria\n",
        "    ax.matshow(images[i])\n",
        "    ax.axis('off')\n",
        "\n",
        "# mostrar la figura\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "5Q0FPqYOzEox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Ejemplo de etiquetas reales y predichas (puedes reemplazar estos valores con los tuyos)\n",
        "#etiquetas_reales = [1, 0, 1, 1, 0]\n",
        "#etiquetas_predichas = [1, 0, 0, 1, 1]\n",
        "\n",
        "# Calcula la exactitud\n",
        "exactitud = accuracy_score(Y, predicted_labels)\n",
        "\n",
        "print(f\"Exactitud: {exactitud:.2f}\")"
      ],
      "metadata": {
        "id": "MpBcpgsH0Bjr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}